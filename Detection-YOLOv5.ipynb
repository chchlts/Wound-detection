{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d554d4e8",
   "metadata": {},
   "source": [
    "# Install YOLOv5 Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2341bd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clone YOLOv5 repository\n",
    "!git clone https://github.com/ultralytics/yolov5 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "677823e0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\Documents\\SKRIPSI\\Coba\\yolov5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\user\\\\Documents\\\\SKRIPSI\\\\Coba\\\\yolov5'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Run this cell for initial set up on YOLOv5 PyTorch\n",
    "\n",
    "# !git clone https://github.com/ultralytics/yolov5\n",
    "%cd yolov5\n",
    "# !pip install -r requirements.txt \n",
    "\n",
    "#make sure you ar on /yolov5 directories\n",
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f119b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install --upgrade pip"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "909c7af9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not open requirements file: [Errno 2] No such file or directory: 'requirements.txt'\n"
     ]
    }
   ],
   "source": [
    "# install dependencies as necessary\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1532c8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import cv2\n",
    "import os\n",
    "import time\n",
    "\n",
    "# to display images\n",
    "from IPython.display import Image, clear_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "756c03db",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ec77da9",
   "metadata": {},
   "source": [
    "## Dataset preparation\n",
    "\n",
    "Make sure that the directory is outside the current directory of yolov5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d42b50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell for initial setup on Roboflow\n",
    "# pip install roboflow --user\n",
    "\n",
    "from roboflow import Roboflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6f37fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import Dataset from roboflow\n",
    "\n",
    "rf = Roboflow(api_key=\"WYy7UTxLiklRVM4VChB0\")\n",
    "project = rf.workspace(\"wound\").project(\"wound-detection\")\n",
    "dataset = project.version(4).download(\"yolov5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0189b309",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip list\n",
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d51c898",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try on pre trained model Run this cell if you want to know\n",
    "\n",
    "# Download pre trained model from torch hub and ultralytics yolov5\n",
    "\n",
    "# model = torch.hub.load('ultralytics/yolov5', 'yolov5s')\n",
    "\n",
    "# Test to create prediction from pretrained model on one data\n",
    "\n",
    "# img = 'https://img.jakpost.net/c/2020/10/31/2020_10_31_106644_1604140506._large.jpg'\n",
    "# results = model(img)\n",
    "# results.print()\n",
    "# results.save()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcb5e2d0",
   "metadata": {},
   "source": [
    "### REAL TIME DETECTION\n",
    "\n",
    "A real time detection using openCV VideoCapture frame as prediction data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60fcea8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cap = cv2.VideoCapture(1)\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    \n",
    "    # Make detections \n",
    "    results = model(frame)\n",
    "    \n",
    "    cv2.imshow('YOLO', np.squeeze(results.render()))\n",
    "    \n",
    "    if cv2.waitKey(10) & 0xFF == ord('q'):\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a0b8d",
   "metadata": {},
   "source": [
    "# TRAIN ON CUSTOM MODEL\n",
    "\n",
    "## Data and configuration preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "258a8a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define number of classes based on data.yaml there is one class on this dataset which is wound\n",
    "import yaml\n",
    "\n",
    "with open(\"../Wound-detection-4/data.yaml\", 'r') as stream:\n",
    "    num_classes = str(yaml.safe_load(stream)['nc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "def60544",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e7b6bdaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize iPython writefile\n",
    "from IPython.core.magic import register_line_cell_magic\n",
    "\n",
    "@register_line_cell_magic\n",
    "def writetemplate(line, cell):\n",
    "    with open(line, 'w') as f:\n",
    "        f.write(cell.format(**globals()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2cb1a2d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-11-841f66f1d33f>, line 14)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-11-841f66f1d33f>\"\u001b[1;36m, line \u001b[1;32m14\u001b[0m\n\u001b[1;33m    anchors:\u001b[0m\n\u001b[1;37m            ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "# Create custom configuration of related models. The models configuration pytorch provides store in /yolov5/models copy\n",
    "# the file and set your own configuration for hyper parameter tunning\n",
    "\n",
    "# YOLOv5s model configuration\n",
    "\n",
    "%%writetemplate models/custom_yolov5s.yaml\n",
    "\n",
    "# parameters\n",
    "nc: 1  # number of classes\n",
    "depth_multiple: 0.67  # model depth multiple\n",
    "width_multiple: 0.75  # layer channel multiple\n",
    "\n",
    "# anchors\n",
    "anchors:\n",
    "  - [10,13, 16,30, 33,23]  # P3/8\n",
    "  - [30,61, 62,45, 59,119]  # P4/16\n",
    "  - [116,90, 156,198, 373,326]  # P5/32\n",
    "\n",
    "# YOLOv5 backbone\n",
    "backbone:\n",
    "  # [from, number, module, args]\n",
    "  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n",
    "   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n",
    "   [-1, 3, C3, [128]],\n",
    "   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n",
    "   [-1, 9, C3, [256]],\n",
    "   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n",
    "   [-1, 9, C3, [512]],\n",
    "   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n",
    "   [-1, 1, SPP, [1024, [5, 9, 13]]],\n",
    "   [-1, 3, C3, [1024, False]],  # 9\n",
    "  ]\n",
    "\n",
    "# YOLOv5 head\n",
    "head:\n",
    "  [[-1, 1, Conv, [512, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n",
    "   [-1, 3, C3, [512, False]],  # 13\n",
    "\n",
    "   [-1, 1, Conv, [256, 1, 1]],\n",
    "   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n",
    "   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n",
    "   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n",
    "\n",
    "   [-1, 1, Conv, [256, 3, 2]],\n",
    "   [[-1, 14], 1, Concat, [1]],  # cat head P4\n",
    "   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n",
    "\n",
    "   [-1, 1, Conv, [512, 3, 2]],\n",
    "   [[-1, 10], 1, Concat, [1]],  # cat head P5\n",
    "   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n",
    "\n",
    "   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n",
    "  ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48deca6",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa1e745b",
   "metadata": {},
   "source": [
    "#### Parameters definitions:\n",
    "\n",
    "- img: refers to the input images size.\n",
    "- batch: refers to the batch size (number of training examples utilized in one iteration).\n",
    "- epochs: refers to the number of training epochs. An epoch corresponds to one cycle through the full training dataset.\n",
    "- data: refers to the path to the yaml file.\n",
    "- cfg: define the model configuration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d780f3ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.dockerignore',\n",
       " '.git',\n",
       " '.gitattributes',\n",
       " '.github',\n",
       " '.gitignore',\n",
       " '.pre-commit-config.yaml',\n",
       " 'classify',\n",
       " 'CONTRIBUTING.md',\n",
       " 'data',\n",
       " 'detect.py',\n",
       " 'export.py',\n",
       " 'hubconf.py',\n",
       " 'LICENSE',\n",
       " 'models',\n",
       " 'README.md',\n",
       " 'requirements.txt',\n",
       " 'setup.cfg',\n",
       " 'train.py',\n",
       " 'tutorial.ipynb',\n",
       " 'utils',\n",
       " 'val.py']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "82afc58a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 0 ns\n"
     ]
    }
   ],
   "source": [
    "%time\n",
    "!python train.py --img 416 --batch 16 --epochs 3 --data ../Wound-detection-4/data.yaml --cfg models/yolov5s.yaml --weights ../yolov5s.pt --cache"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c82699f",
   "metadata": {},
   "source": [
    "### Evaluate the training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ae6498c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.plots import plot_results  # plot results.txt as results.png\n",
    "# Image(filename='runs/train/exp/results.png', width=1000)\n",
    "\n",
    "\n",
    "# from object_detection.utils.plots import plot_results\n",
    "plot_results('runs/train/exp/results.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
